{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jarvis\n",
    "This notebook implements a chatbot from YouTube based on groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import cv2\n",
    "import pyperclip\n",
    "from PIL import ImageGrab, Image\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "web_cam = cv2.VideoCapture(0)\n",
    "\n",
    "sys_msg = (\n",
    "    'You are a multi-modal AI voice assistant. Your user may or may not have attached a photo for context '\n",
    "    '(either a screenshot or a webcam capture). Any photo has already been processed into a hihgly detailed '\n",
    "    'text prompt that will be attached to their transcribed vocie propmt. Generate the most usefil and '\n",
    "    'factual response possible, carefully considering all previous generated test in your response before '\n",
    "    'adding new tokens to the response. Do not expect or request images, just use the context if added. '\n",
    "    'Use all of the context of this conversation so your response is relevant to the conversation. Make '\n",
    "    'your responses clear and concise, avoiding any verbosity.'\n",
    ")\n",
    "\n",
    "convo = [{'role': 'system', 'content': sys_msg}]\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "generation_config = {\n",
    "    'temperature': 0.7,\n",
    "    'top_p': 1,\n",
    "    'top_k': 1,\n",
    "    'max_output_tokens': 2048\n",
    "}\n",
    "safety_settings = [\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_HARASSMENT',\n",
    "        'threshold': 'BLOCK_NONE'\n",
    "    },\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_HATE_SPEECH',\n",
    "        'threshold': 'BLOCK_NONE'\n",
    "    },\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n",
    "        'threshold': 'BLOCK_NONE'\n",
    "    },\n",
    "    {\n",
    "        'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n",
    "        'threshold': 'BLOCK_NONE'\n",
    "    },\n",
    "]\n",
    "vision_model = genai.GenerativeModel('gemini-1.5-flash-latest',\n",
    "                                    generation_config=generation_config,\n",
    "                                    safety_settings=safety_settings)\n",
    "groq_client = Groq()\n",
    "\n",
    "def groq_prompt(prompt, img_context=None):\n",
    "    if img_context:\n",
    "        prompt = f'USER_PROMPT: {prompt}\\n\\n   IMAGE CONTEXT: {img_context}'\n",
    "    convo.append({'role': 'user', 'content': prompt})\n",
    "    chat_completion = groq_client.chat.completions.create(messages=convo, model=\"llama3-70b-8192\")\n",
    "\n",
    "    response = chat_completion.choices[0].message\n",
    "    convo.append(response)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is David Lawrence's favorite comedian? Bill Ba-ray-dee. I'll see myself out.\n"
     ]
    }
   ],
   "source": [
    "# test the prompt\n",
    "prompt = input('USER: ')\n",
    "response = groq_prompt(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def function_call(prompt):\n",
    "    sys_msg = (\n",
    "        'You are an AI function calling model. You will determine which function from this list: '\n",
    "        '[\"extract clipboard\", \"take screenshot\", \"capture webcam\", \"None\"] should be called to gain the context '\n",
    "        'for another AI to respond to the user. You are not responding to the user. You should only return one value from the list. '\n",
    "        'If the user asks for help with something on their screen you should respond with \"take screen shot\". '\n",
    "        'If the user asks for help on something in their environment or their physical appearance you should respond with \"capture webcam\". '\n",
    "        'If the user asks for help with their clipboard content you should respond with \"extract clipboard\". '\n",
    "        'If none of the previous options are appropriate respond with \"None\". Only respond woth one value from the list and do not provide any explanation.'\n",
    "    ) \n",
    "\n",
    "    function_convo = [{'role': 'system', 'content': sys_msg},\n",
    "                      {'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    chat_completion = groq_client.chat.completions.create(messages=function_convo, model=\"mixtral-8x7b-32768\")\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def take_screenshot():\n",
    "    path = 'screenshot.jpg'\n",
    "    screenshot = ImageGrab.grab()\n",
    "    rgb_screenshot = screenshot.convert('RGB')\n",
    "    rgb_screenshot.save(path, quality=15)\n",
    "\n",
    "\n",
    "def web_cam_capture():\n",
    "    if not web_cam.isOpened():\n",
    "        print('Error: Camera did not open successfully')\n",
    "        return\n",
    "    \n",
    "    path = 'webcam.jpg'\n",
    "    ret, frame = web_cam.read()\n",
    "    cv2.imwrite(path, frame)\n",
    "\n",
    "\n",
    "def get_clipboard_text():\n",
    "    clipboard_content = pyperclip.paste()\n",
    "    if isinstance(clipboard_content, str):\n",
    "        return clipboard_content\n",
    "    else:\n",
    "        print('Error: Clipboard content is not a string')\n",
    "        return None\n",
    "\n",
    "def vision_prompt(prompt, photo_path):\n",
    "    img = Image.open(photo_path)\n",
    "    prompt = (\n",
    "        'You are the vision analysis AI that provides semantic meaning from images to provide context '\n",
    "        'to send to another AI that will create a response to the user. Do not respond as the AI assistant '\n",
    "        'to the user. Instead take the user prompt input and try to extract all meaning from the photo '\n",
    "        'relevant to the user prompt. Then generate as much objective data about the image for the AI '\n",
    "        'assistant who will respond to the user. \\nUSER PROMPT: {prompt}'\n",
    "    )\n",
    "    response = vision_model.generate_content([prompt, img])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract clipboard\n",
      "\"capture webcam\"\n"
     ]
    }
   ],
   "source": [
    "prompt = 'I want you to analyse the code I put on the clipboard.'\n",
    "response = function_call(prompt)\n",
    "print(response)\n",
    "print(function_call(\"I am holding amy dog up to the webcam. What is on his nose?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web_cam_capture()\n",
      "take_screenshot()\n",
      "print(get_clipboard_text())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "web_cam_capture()\n",
    "take_screenshot()\n",
    "print(get_clipboard_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jarvis():\n",
    "    finished = False\n",
    "    while finished == False:\n",
    "        visual_context=None\n",
    "        prompt = input('USER: ')\n",
    "        if 'bye' in prompt.lower():\n",
    "            finished=True\n",
    "            print('Bye')\n",
    "            break\n",
    "\n",
    "        call = function_call(prompt)\n",
    "        call = call.lower()\n",
    "        print(call)\n",
    "\n",
    "        if 'take screenshot' in call:\n",
    "            print('taking screenshot')\n",
    "            take_screenshot()\n",
    "            visual_context = vision_prompt(prompt, photo_path='screenshot.jpg')\n",
    "            print(f'screenshot: {visual_context}')\n",
    "        \n",
    "        elif 'capture webcam' in call:\n",
    "            print('capturing webcam')\n",
    "            web_cam_capture()\n",
    "            visual_context = vision_prompt(prompt, photo_path='webcam.jpg')\n",
    "            print(f'webcam: {visual_context}')\n",
    "\n",
    "        elif 'extract clipboard' in call:\n",
    "            print('Copying clipboard text')\n",
    "            paste = get_clipboard_text()\n",
    "            prompt = f'{prompt}\\n\\n CLIPBOARD CONTENT: {paste}'\n",
    "            print(f'clipboard: {paste}')\n",
    "            visual_context = None\n",
    "\n",
    "        response = groq_prompt(prompt=prompt, img_context=visual_context)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"none\"\n",
      "Hello! It's nice to meet you. I'm here to help with any questions or topics you'd like to discuss. What's on your mind today?\n",
      "none\n",
      "I'm happy to help! However, I don't have any visual information about you, so I can't tell what color jumper you're wearing. If you'd like to share a photo or describe what you're wearing, I'd be happy to try and help you with that!\n",
      "\"take screenshot\"\n",
      "taking screenshot\n",
      "screenshot: ```json\n",
      "{\n",
      "  \"code\": \"jarvis.ipynb\",\n",
      "  \"code_language\": \"python\",\n",
      "  \"code_snippet\": \"print('capturing webcam')\\nweb_cam_capture()\\nvisual_context = vision_prompt(prompt, photo_path='webcam.jpg')\\nprint(f'webcam: {visual_context}')\",\n",
      "  \"code_description\": \"This code snippet is part of a larger Python program that takes a user prompt and attempts to extract visual context from an image. It first captures an image from the webcam and then calls a function, `vision_prompt`, which is likely responsible for analyzing the image and extracting relevant information. The extracted visual context is then printed to the console.\",\n",
      "  \"code_purpose\": \"The purpose of this code is to capture an image from the webcam, analyze it, and extract visual context that can be used to provide a more relevant response to the user.\",\n",
      "  \"user_input\": \"This is a user input.\",\n",
      "  \"user_intent\": \"The user is asking for something, perhaps about the image.\",\n",
      "  \"image_description\": \"The image is a screenshot of a code editor with Python code displayed. The code is related to capturing a webcam image and extracting visual context from it. \",\n",
      "  \"image_type\": \"screenshot\",\n",
      "  \"image_items\": [\n",
      "    \"code editor\",\n",
      "    \"python code\",\n",
      "    \"webcam capture\",\n",
      "    \"visual context extraction\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Based on the image context, it appears that you have a code editor open on your screen, and the code is related to capturing a webcam image and extracting visual context from it. Specifically, the code snippet is written in Python and includes a function call to capture a webcam image and then extract visual context from it.\n",
      "Bye\n"
     ]
    }
   ],
   "source": [
    "jarvis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
