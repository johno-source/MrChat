{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI API Chat\n",
    "The aim of this notebook is to explore the creation of memories using open ai models via their api.\n",
    "\n",
    "This code should be run in the conda environment: reflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8', errors='ignore') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "\n",
    "openai.api_key = open_file('key_openai.txt').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = openai.Model.list()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"MAIN PURPOSE\n",
    "You are a Reflective Journaling chatbot, designed with the primary objective of facilitating users in their exploration of thoughts and feelings. Your main task is to act as a catalyst in their journey of self-discovery and personal growth. Remember, the overall purpose is not just to document the user's thoughts and feelings, but to support their journey towards deeper self-understanding and growth in a natural, human-like conversational tone.\n",
    "\n",
    "\n",
    "BEHAVIORS AND METHODS\n",
    "The following are guidelines for your behaviors and methodology of engagement.\n",
    "\n",
    "Deep Dive: Encourage users to venture into the depths of their thoughts and emotions. Your dialogue should nudge them towards introspection, revealing layers of their psyche they might not be aware of. Ask pointed and exploratory questions, but do so in a smooth, conversational manner that feels less like an interrogation and more like a friendly chat.\n",
    "\n",
    "Engage with Empathy: Provide validation when users express their feelings or ideas. This will help build trust and make them more comfortable sharing deeper aspects of themselves. Be aware, though, of avoiding undue affirmation of negative or unproductive thinking patterns.\n",
    "\n",
    "Reframing and Reflection: When you detect unhelpful thought patterns, guide the user towards reframing their perspective. Do not impose a new frame, but gently nudge them to see the situation from different angles. Take note of recurring themes or patterns in their entries and reflect on them.\n",
    "\n",
    "Educate and Enlighten: Where appropriate, introduce new concepts, techniques, or information that may help the user better understand their emotions and experiences. This should be done in a non-intrusive way, embedded naturally within the conversation.\n",
    "\n",
    "The Core Issue: Your goal isn't to simply hear the user's thoughts, but to help them uncover the core issues driving their feelings and behavior. Read between the lines, use your understanding of their past entries to discern underlying themes, and gently lead them towards these revelations.\n",
    "\n",
    "Read Between The Lines: Use your ability to infer what is going on to see the bigger picture and read between the lines. If you perceive that the user may not be focusing the most emotionally salient topic, call their attention to the broader range of emotional content. The reason for this is that not all users are fully emotionally literate, or they may be in a sub-optimal state. \n",
    "\n",
    "Natural Flow: The overall tone of the conversation should be easy-going, natural, and conversational. Avoid blunt, robotic responses. Do not use lists ever. Instead, aim for subtlety, nuance, and a gentle, guiding style.\n",
    "\n",
    "Ask Questions: Whether you ask probing questions or leading questions, you should use questions as much as possible to solicit deeper reflection. Make observations and connect dots, and ask if the user noticed the patterns.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the model with some test code\n",
    "conversation = list()\n",
    "conversation.append({'role': 'user', 'content': 'Explain the difference between a hybrid car and an electric car.'})\n",
    "conversation.append({'role': 'system', 'content': system_message})\n",
    "\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo-0613', messages=conversation, temperature=0)\n",
    "text = response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def fmt(response):\n",
    "    formatted_lines = [textwrap.fill(line, width=120, initial_indent='    ', subsequent_indent='    ') for line in response.split('\\n')]\n",
    "    return '\\n'.join(formatted_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sure! I'd be happy to explain the difference between a hybrid car and an electric car.\n",
      "\n",
      "    A hybrid car is a vehicle that combines two different power sources to propel itself. Typically, a hybrid car has\n",
      "    both an internal combustion engine (usually fueled by gasoline) and an electric motor. The electric motor is powered\n",
      "    by a battery that is charged through regenerative braking or by the internal combustion engine. The main purpose of\n",
      "    a hybrid car is to improve fuel efficiency and reduce emissions by using the electric motor for low-speed driving or\n",
      "    when extra power is needed.\n",
      "\n",
      "    On the other hand, an electric car, also known as an electric vehicle (EV), is powered solely by an electric motor\n",
      "    and a battery pack. It does not have an internal combustion engine and does not require gasoline or any other fossil\n",
      "    fuel. Electric cars are charged by plugging them into an electrical outlet or a charging station. They rely entirely\n",
      "    on electricity to operate and produce zero tailpipe emissions, making them more environmentally friendly compared to\n",
      "    traditional gasoline-powered vehicles.\n",
      "\n",
      "    In summary, the main difference between a hybrid car and an electric car lies in their power sources. A hybrid car\n",
      "    combines an internal combustion engine with an electric motor, while an electric car relies solely on an electric\n",
      "    motor and a battery pack. Both types of vehicles aim to reduce fuel consumption and emissions, but electric cars\n",
      "    offer a more sustainable and zero-emission solution.\n"
     ]
    }
   ],
   "source": [
    "print(fmt(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'object', 'created', 'model', 'choices', 'usage'])\n",
      "chatcmpl-7knNtaLQWSkNf3Wncqbih63wzg7XP\n",
      "chat.completion\n",
      "1691387277\n",
      "gpt-3.5-turbo-0613\n",
      "1\n",
      "dict_keys(['index', 'message', 'finish_reason'])\n",
      "0\n",
      "function_call\n",
      "dict_keys(['prompt_tokens', 'completion_tokens', 'total_tokens'])\n",
      "56\n",
      "7\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "print(response.keys())\n",
    "print(response['id'])\n",
    "print(response['object'])\n",
    "print(response['created'])\n",
    "print(response['model'])\n",
    "print(len(response['choices']))\n",
    "print(response['choices'][0].keys())\n",
    "print(response['choices'][0]['index'])\n",
    "print(response['choices'][0]['finish_reason'])\n",
    "print(response['usage'].keys())\n",
    "print(response['usage']['prompt_tokens'])\n",
    "print(response['usage']['completion_tokens'])\n",
    "print(response['usage']['total_tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-08-2023 05:47:57\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def linux_time_to_date(linux_time):\n",
    "    date_time = datetime.datetime.fromtimestamp(linux_time)\n",
    "    return date_time.strftime('%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "print(linux_time_to_date(response['created']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to do things. We could get the chatbot to make callbacks to invoke memories or we could design a prompt that extracts the types of memories that we want to recall.\n",
    "Lets try both.\n",
    "\n",
    "First let's get it to answer a simple question that will require a callback: What is today's date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = list()\n",
    "conversation.append({'role': 'user', 'content': \"What is today's date?\"})\n",
    "conversation.append({'role': 'system', 'content': \"You are a helpful assistant.\"})\n",
    "\n",
    "functions = list()\n",
    "functions.append({'name' : 'GetCurrentDateTime', 'description': \"Get's the current date and time.\", 'parameters': {'type': 'object', 'properties': {}}})\n",
    "\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo-0613', messages=conversation, functions=functions, temperature=0)\n",
    "text = response['choices'][0]['message']['content']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"GetCurrentDateTime\",\n",
      "  \"arguments\": \"{}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['function_call'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCurrentDateTime():\n",
    "    return str(datetime.datetime.now().strftime('%d-%m-%Y %H:%M:%S'))\n",
    "\n",
    "extend_conversation = list()\n",
    "extend_conversation.extend(conversation)\n",
    "extend_conversation.append(response['choices'][0]['message'])\n",
    "extend_conversation.append({ 'role' : 'function', 'name' : 'GetCurrentDateTime', 'content' : GetCurrentDateTime() })\n",
    "\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo-0613', messages=extend_conversation, temperature=0)\n",
    "text = response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07-08-2023 06:13:40'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime('%d-%m-%Y %H:%M:%S')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - that worked. Lets make it more specific to the problem we are addressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = list()\n",
    "conversation.append({'role': 'user', 'content': \"What did we speak about yesterday?\"})\n",
    "conversation.append({'role': 'system', 'content': \"You are a helpful assistant.\"})\n",
    "\n",
    "functions = list()\n",
    "functions.append({'name' : 'GetCurrentDateTime', 'description': \"Get's the current date and time.\", 'parameters': {'type': 'object', 'properties': {}}})\n",
    "functions.append({'name' : 'RecallMemory', 'description': \"Recalls the conversation at a given time formatted as json.\", 'parameters': {\n",
    "    'type': 'object', 'properties': { \n",
    "        'time' : { \n",
    "            'type': 'string',\n",
    "            'description': 'The time formatted as mm:dd:yyyy hh:mm:ss.'\n",
    "            }\n",
    "        }\n",
    "    }})\n",
    "\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo-0613', messages=conversation, functions=functions, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'object', 'created', 'model', 'choices', 'usage'])\n",
      "chatcmpl-7koCUircdL8syt0yJNHDrv3UTG8b7\n",
      "chat.completion\n",
      "1691390414\n",
      "gpt-3.5-turbo-0613\n",
      "1\n",
      "dict_keys(['index', 'message', 'finish_reason'])\n",
      "0\n",
      "function_call\n",
      "{\n",
      "  \"name\": \"GetCurrentDateTime\",\n",
      "  \"arguments\": \"{}\"\n",
      "}\n",
      "dict_keys(['prompt_tokens', 'completion_tokens', 'total_tokens'])\n",
      "96\n",
      "7\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "print(response.keys())\n",
    "print(response['id'])\n",
    "print(response['object'])\n",
    "print(response['created'])\n",
    "print(response['model'])\n",
    "print(len(response['choices']))\n",
    "print(response['choices'][0].keys())\n",
    "print(response['choices'][0]['index'])\n",
    "print(response['choices'][0]['finish_reason'])\n",
    "print(response['choices'][0]['message']['function_call'])\n",
    "print(response['usage'].keys())\n",
    "print(response['usage']['prompt_tokens'])\n",
    "print(response['usage']['completion_tokens'])\n",
    "print(response['usage']['total_tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list()\n",
    "c.extend(conversation)\n",
    "c.append(response['choices'][0]['message'])\n",
    "c.append({ 'role' : 'function', 'name' : 'GetCurrentDateTime', 'content' : GetCurrentDateTime() })\n",
    "\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo-0613', messages=c, functions=functions, temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'object', 'created', 'model', 'choices', 'usage'])\n",
      "chatcmpl-7koDL3hoXsLdiPRlrMbI56T9VanXT\n",
      "chat.completion\n",
      "1691390467\n",
      "gpt-3.5-turbo-0613\n",
      "1\n",
      "dict_keys(['index', 'message', 'finish_reason'])\n",
      "0\n",
      "function_call\n",
      "{\n",
      "  \"name\": \"RecallMemory\",\n",
      "  \"arguments\": \"{\\n  \\\"time\\\": \\\"07-07-2023\\\"\\n}\"\n",
      "}\n",
      "dict_keys(['prompt_tokens', 'completion_tokens', 'total_tokens'])\n",
      "129\n",
      "21\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(response.keys())\n",
    "print(response['id'])\n",
    "print(response['object'])\n",
    "print(response['created'])\n",
    "print(response['model'])\n",
    "print(len(response['choices']))\n",
    "print(response['choices'][0].keys())\n",
    "print(response['choices'][0]['index'])\n",
    "print(response['choices'][0]['finish_reason'])\n",
    "print(response['choices'][0]['message']['function_call'])\n",
    "print(response['usage'].keys())\n",
    "print(response['usage']['prompt_tokens'])\n",
    "print(response['usage']['completion_tokens'])\n",
    "print(response['usage']['total_tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list()\n",
    "d.extend(conversation)\n",
    "d.append(response['choices'][0]['message'])\n",
    "d.append({ 'role' : 'function', 'name' : 'RecallMemory', 'content' : \"{ 'time' : '07-07-2023 12:30:00', 'topic' : 'Electric Vehicles' }\" })\n",
    "\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo-0613', messages=d, functions=functions, temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'object', 'created', 'model', 'choices', 'usage'])\n",
      "chatcmpl-7koLloXmkaloo7nNAlE0Xikby1KaE\n",
      "chat.completion\n",
      "1691390989\n",
      "gpt-3.5-turbo-0613\n",
      "1\n",
      "dict_keys(['index', 'message', 'finish_reason'])\n",
      "0\n",
      "stop\n",
      "Yesterday, we spoke about electric vehicles.\n",
      "dict_keys(['prompt_tokens', 'completion_tokens', 'total_tokens'])\n",
      "154\n",
      "9\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print(response.keys())\n",
    "print(response['id'])\n",
    "print(response['object'])\n",
    "print(response['created'])\n",
    "print(response['model'])\n",
    "print(len(response['choices']))\n",
    "print(response['choices'][0].keys())\n",
    "print(response['choices'][0]['index'])\n",
    "print(response['choices'][0]['finish_reason'])\n",
    "print(response['choices'][0]['message']['content'])\n",
    "print(response['usage'].keys())\n",
    "print(response['usage']['prompt_tokens'])\n",
    "print(response['usage']['completion_tokens'])\n",
    "print(response['usage']['total_tokens'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reflect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
